{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "traindir = '/home/saniea/imagedata/cifar10/'\n",
    "valdir = '/home/saniea/imagedata/cifar10/test_batch'\n",
    "train, test = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def convert(data):\n",
    "    # magic recursive function\n",
    "    if isinstance(data, bytes):      return data.decode('ascii')\n",
    "    if isinstance(data, dict):       return dict(map(convert, data.items()))\n",
    "    if isinstance(data, tuple):      return map(convert, data)\n",
    "    if isinstance(data, list):       return list(map(convert, data))\n",
    "    return data\n",
    "\n",
    "# TO DO: function to print image if needed\n",
    "# X = X.reshape(50000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "# # X = X.reshape(50000, 3, 32, 32)\n",
    "# # X = X.transpose(0, 2, 3, 1)\n",
    "# plt.imshow(X[5], interpolation='none')\n",
    "# plt.colorbar()\n",
    "# print(label_names[int(Y[5])])\n",
    "# plt.figure()\n",
    "# plt.imshow(X[7])\n",
    "# print(label_names[int(Y[7])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (50000, 3072)\n",
      "Training labels size: 50000\n",
      "Validation data size: (10000, 3072)\n",
      "Validation labels size: 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for root, dirs, filenames in os.walk(traindir):\n",
    "#     files = filenames\n",
    "# # print(files)\n",
    "\n",
    "# data = [] # list of all training data files to be unpacked, total 50k images\n",
    "# [data.append(file) for file in files if (file.startswith('data') == True)]\n",
    "# data.sort()\n",
    "# # print(data)\n",
    "\n",
    "# test = unpickle(str(traindir+'data_batch_1'))\n",
    "# # print(test.keys())\n",
    "\n",
    "# X = np.empty((50000,3072))\n",
    "# Y = np.empty((50000))\n",
    "# batch_len = 10000\n",
    "\n",
    "# for i, batch in enumerate (data):\n",
    "#     batch = unpickle(str(traindir+batch))\n",
    "#     current_batch = {k.decode() : v for k, v in batch.items()}\n",
    "#     X[batch_len*i:batch_len*(i+1)] = current_batch['data']\n",
    "#     Y[batch_len*i:batch_len*(i+1)] = current_batch['labels']\n",
    "#     # i = 0, index(j) = i + 1 = 1 --> 00000 - 10000\n",
    "#     # i = 1, index(j) = i + 1 = 2 --> 10000 - 20000\n",
    "#     # i = 2, index(j) = i + 1 = 3 --> 20000 - 30000\n",
    "\n",
    "# meta_b = unpickle(str(traindir+'batches.meta'))\n",
    "# meta = {k.decode() : v for k, v in meta_b.items()}\n",
    "# label_names = meta['label_names']\n",
    "\n",
    "# # test_batch = unpickle(valdir)\n",
    "# val_batch = {k.decode():v for k, v in unpickle(valdir).items()}\n",
    "# X_val = val_batch['data']\n",
    "# Y_val = val_batch['labels']\n",
    "    \n",
    "# print('Training data size: ' + str(X.shape) + '\\n'\n",
    "#      +'Training labels size: ' + str(len(Y)) + '\\n'\n",
    "#      +'Validation data size: ' + str(X_val.shape) + '\\n'\n",
    "#      +'Validation labels size: ' + str(len(Y_val)) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (50000, 32, 32, 3)\n",
      "Training labels size: 50000\n",
      "Validation data size: (10000, 32, 32, 3)\n",
      "Validation labels size: 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = train[0]\n",
    "y_train = train[1]\n",
    "\n",
    "x_val = test[0]\n",
    "y_val = test[1]\n",
    "    \n",
    "print('Training data size: ' + str(x_train.shape) + '\\n'\n",
    "     +'Training labels size: ' + str(len(y_train)) + '\\n'\n",
    "     +'Validation data size: ' + str(x_val.shape) + '\\n'\n",
    "     +'Validation labels size: ' + str(len(y_val)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(50000, 32, 32, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 8)         224       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 30, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 8)         584       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          1168      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,386\n",
      "Trainable params: 4,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 71s 1s/step - loss: 2.2256 - acc: 0.1794 - val_loss: 2.0694 - val_acc: 0.2914\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 62s 1s/step - loss: 2.0655 - acc: 0.2410 - val_loss: 1.9250 - val_acc: 0.3280\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 62s 1s/step - loss: 1.9856 - acc: 0.2659 - val_loss: 1.8524 - val_acc: 0.3468\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 62s 1s/step - loss: 1.9338 - acc: 0.2837 - val_loss: 1.8077 - val_acc: 0.3510\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.8964 - acc: 0.2973 - val_loss: 1.7829 - val_acc: 0.3534\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.8665 - acc: 0.3088 - val_loss: 1.7663 - val_acc: 0.3558\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.8434 - acc: 0.3176 - val_loss: 1.7272 - val_acc: 0.3760\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.8226 - acc: 0.3254 - val_loss: 1.7449 - val_acc: 0.3666\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.8044 - acc: 0.3321 - val_loss: 1.6876 - val_acc: 0.3878\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7930 - acc: 0.3368 - val_loss: 1.6740 - val_acc: 0.3970\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7759 - acc: 0.3429 - val_loss: 1.6817 - val_acc: 0.3912\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7673 - acc: 0.3471 - val_loss: 1.6459 - val_acc: 0.4062\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7570 - acc: 0.3511 - val_loss: 1.6366 - val_acc: 0.4088\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7443 - acc: 0.3557 - val_loss: 1.6621 - val_acc: 0.4038\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7359 - acc: 0.3595 - val_loss: 1.6095 - val_acc: 0.4186\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7261 - acc: 0.3633 - val_loss: 1.6159 - val_acc: 0.4104\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7184 - acc: 0.3663 - val_loss: 1.5974 - val_acc: 0.4290\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7091 - acc: 0.3699 - val_loss: 1.6003 - val_acc: 0.4264\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.7014 - acc: 0.3733 - val_loss: 1.6080 - val_acc: 0.4208\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.6945 - acc: 0.3756 - val_loss: 1.5799 - val_acc: 0.4322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f89ea6facc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(8, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train / 255.0       # as suggested in Tensorflow tutorial, to normalize the images. now, b&w\n",
    "y_train = to_categorical(y_train)\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(x = x_train,\n",
    "          y = y_train,\n",
    "          epochs = 20,\n",
    "          steps_per_epoch= x_train.shape[0] // batch_size,\n",
    "          validation_split = 0.1,\n",
    "          validation_steps = 10)\n",
    "\n",
    "# model.save_weights('attempt_1.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
